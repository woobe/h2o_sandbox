{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:92: DeprecationWarning: DisplayFormatter._ipython_display_formatter_default is deprecated: use @default decorator instead.\n",
      "  def _ipython_display_formatter_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:98: DeprecationWarning: DisplayFormatter._formatters_default is deprecated: use @default decorator instead.\n",
      "  def _formatters_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime: </td>\n",
       "<td>7 seconds 213 milliseconds </td></tr>\n",
       "<tr><td>H2O cluster version: </td>\n",
       "<td>3.8.2.6</td></tr>\n",
       "<tr><td>H2O cluster name: </td>\n",
       "<td>sparkling-water-jchow_115504489</td></tr>\n",
       "<tr><td>H2O cluster total nodes: </td>\n",
       "<td>3</td></tr>\n",
       "<tr><td>H2O cluster total free memory: </td>\n",
       "<td>2.88 GB</td></tr>\n",
       "<tr><td>H2O cluster total cores: </td>\n",
       "<td>24</td></tr>\n",
       "<tr><td>H2O cluster allowed cores: </td>\n",
       "<td>24</td></tr>\n",
       "<tr><td>H2O cluster healthy: </td>\n",
       "<td>True</td></tr>\n",
       "<tr><td>H2O Connection ip: </td>\n",
       "<td>172.16.2.93</td></tr>\n",
       "<tr><td>H2O Connection port: </td>\n",
       "<td>54327</td></tr>\n",
       "<tr><td>H2O Connection proxy: </td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python Version: </td>\n",
       "<td>2.7.6</td></tr></table></div>"
      ],
      "text/plain": [
       "------------------------------  -------------------------------\n",
       "H2O cluster uptime:             7 seconds 213 milliseconds\n",
       "H2O cluster version:            3.8.2.6\n",
       "H2O cluster name:               sparkling-water-jchow_115504489\n",
       "H2O cluster total nodes:        3\n",
       "H2O cluster total free memory:  2.88 GB\n",
       "H2O cluster total cores:        24\n",
       "H2O cluster allowed cores:      24\n",
       "H2O cluster healthy:            True\n",
       "H2O Connection ip:              172.16.2.93\n",
       "H2O Connection port:            54327\n",
       "H2O Connection proxy:\n",
       "Python Version:                 2.7.6\n",
       "------------------------------  -------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2OContext: ip=172.16.2.93, port=54327 (open UI at http://172.16.2.93:54327 )\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "## Read MNIST data into H2O\n",
    "from pysparkling import H2OContext\n",
    "h2o.__version__\n",
    "hc = H2OContext(sc).start()\n",
    "print(hc)\n",
    "DATASET_DIR=\"http://s3.amazonaws.com/h2o-public-test-data/bigdata/laptop/mnist\"\n",
    "train_frame = h2o.import_file(\"{}/{}\".format(DATASET_DIR, \"train.csv.gz\"))\n",
    "test_frame = h2o.import_file(\"{}/{}\".format(DATASET_DIR, \"test.csv.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## can simulate larger clusters here\n",
    "NODES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sparkling, TensorFlow!', 'Sparkling, TensorFlow!', 'Sparkling, TensorFlow!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Initialize TensorFlow session and test it\n",
    "def map_fun(i):\n",
    "  import tensorflow as tf\n",
    "  with tf.Graph().as_default() as g:\n",
    "    hello = tf.constant('Sparkling, TensorFlow!', name=\"hello_constant\")\n",
    "    with tf.Session() as sess:\n",
    "      return sess.run(hello)\n",
    "sc.parallelize(range(NODES), NODES).map(map_fun).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = hc.as_spark_frame(train_frame).repartition(NODES)\n",
    "test_df = hc.as_spark_frame(test_frame).repartition(NODES)\n",
    "#train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define the number of hidden neurons per layer\n",
    "HN=50\n",
    "\n",
    "# - it loads local training data into numpy array (from Spark -> Python)\n",
    "# - train TF Deep Learning model with 2 hidden layer\n",
    "# - output accuracy on training data\n",
    "def create_nn(data_train, data_test, iterations, batch_size):\n",
    "    ## input\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    ## weights\n",
    "    W = [tf.Variable(tf.random_normal([784,HN],stddev=0.1))\n",
    "        ,tf.Variable(tf.random_normal([HN, HN],stddev=0.1))\n",
    "        ,tf.Variable(tf.random_normal([HN, 10],stddev=0.1))]\n",
    "    ## biases\n",
    "    b = [tf.Variable(tf.random_normal([HN],    stddev=0.1))\n",
    "        ,tf.Variable(tf.random_normal([HN],    stddev=0.1))\n",
    "        ,tf.Variable(tf.random_normal([10],    stddev=0.1))]\n",
    "    ## hidden layer activation\n",
    "    h1 = tf.nn.relu(   tf.matmul(x,  W[0]) + b[0])\n",
    "    h2 = tf.nn.relu(   tf.matmul(h1, W[1]) + b[1])\n",
    "    ## output\n",
    "    y = tf.nn.softmax( tf.matmul(h2, W[2]) + b[2])\n",
    "    ## storage for actual labels\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "    ## cost function\n",
    "    cross_entropy = -tf.reduce_sum(y_*tf.log(y))                    \n",
    "    ## optimizer\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "    \n",
    "    # Train the model\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    print(\"Training TensorFlow Deep Learning model\")\n",
    "    for i in range(iterations):\n",
    "      #print(\"TensorFlow iter: \", i, \" session: \", sess)\n",
    "      batch_xs, batch_ys = data_train.next_batch(batch_size)\n",
    "      sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        \n",
    "    model = [(sess.run(W[0]),sess.run(W[1]),sess.run(W[2]),sess.run(b[0]),sess.run(b[1]),sess.run(b[2]))]\n",
    "\n",
    "    # Model evaluation\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    batch_xs, batch_ys = data_test.next_batch(batch_size)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Training Accuracy:\", sess.run(accuracy, feed_dict={x: batch_xs, y_: batch_ys}))\n",
    "    #print(sess.run(tf.argmax(y,1), feed_dict={x: batch_xs, y_: batch_ys}))\n",
    "    \n",
    "    sess.close()\n",
    "    return iter(model)\n",
    "    \n",
    "    # Export the model\n",
    "    #from tensorflow_serving.session_bundle import exporter\n",
    "    #export_path = \"/tmp/xxx/\"\n",
    "    #saver = tf.train.Saver(sharded=True)\n",
    "    #model_exporter = exporter.Exporter(saver)\n",
    "    #signature = exporter.classification_signature(input_tensor=x, scores_tensor=y)\n",
    "    #model_exporter.init(sess.graph.as_graph_def(), default_graph_signature=signature)\n",
    "    #model_exporter.export(export_path, tf.constant(FLAGS.export_version), sess)\n",
    "    \n",
    "## Internal Helpers\n",
    "\n",
    "# Sampling with replacement to provide a batch size\n",
    "# Load everything into numpy datastructure\n",
    "import numpy as np\n",
    "\n",
    "def expand1hot(response, levels):\n",
    "    nrows = response.shape[0]\n",
    "    result = np.zeros((nrows, levels), dtype=np.float32)\n",
    "    result[np.arange(nrows), response.astype(np.int8)] = 1.0\n",
    "    return result\n",
    "\n",
    "class RowData:\n",
    "    def __init__(self, it):\n",
    "        self._part_array = np.array([ [a for a in x] for x in it], dtype=np.float32)\n",
    "        # Definition of input features\n",
    "        self._x = range(784)\n",
    "        # Index of response\n",
    "        self._y = 784\n",
    "\n",
    "    def next_batch(self, n):\n",
    "        # Sample from local data without replacement\n",
    "        dim = self._part_array.shape[0] # number of rows\n",
    "        sample = np.random.choice(dim, n, replace=False)\n",
    "        data = self._part_array[sample, :]\n",
    "        # Data coming from H2O, pixel values are 0..255 -> normalize to 0..1\n",
    "        # FIXME: this should be done via RDD or H2O API directly !\n",
    "        train = data[:, self._x]/255\n",
    "        response = expand1hot(data[:, self._y], 10)\n",
    "        return (train, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of batches to iterate\n",
    "ITERATIONS = 100\n",
    "# Batch size (per iteration)\n",
    "BATCH_SIZE = 100\n",
    "# Use MNIST dataset provided by TensorFlow - for debugging only\n",
    "USE_TF_MNIST=False\n",
    "\n",
    "def train_nn(iterations, batch_size, use_tf_mnist=False):\n",
    "    def perPartition(it):\n",
    "        if not use_tf_mnist:\n",
    "            train_data = RowData(it)\n",
    "            test_data = train_data\n",
    "        else:\n",
    "            from tensorflow.examples.tutorials.mnist import input_data\n",
    "            mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "            train_data = mnist.train\n",
    "            test_data = mnist.train\n",
    "            \n",
    "        return create_nn(train_data, test_data, iterations, batch_size)\n",
    "        \n",
    "    return perPartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coeffs_per_node = train_df.mapPartitions(train_nn(ITERATIONS, BATCH_SIZE, USE_TF_MNIST)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Now, we have the weights and biases for each node\n",
    "print(len(coeffs_per_node))    ## Number of nodes\n",
    "print(len(coeffs_per_node[0])) ## Number of weight and bias arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "[[50, 784], [50, 50], [10, 50]]\n",
      "[[50, 1], [50, 1], [10, 1]]\n"
     ]
    }
   ],
   "source": [
    "# Average the weights and biases across all node-local models\n",
    "avg_coeffs = [c for c in coeffs_per_node[0]]\n",
    "for i in range(0,len(avg_coeffs)):\n",
    "    for node in range(1,NODES):\n",
    "        avg_coeffs[i] = avg_coeffs[i] + coeffs_per_node[node][i]\n",
    "avg_coeffs = [c/NODES for c in avg_coeffs]\n",
    "\n",
    "num_weights=len(coeffs_per_node[0])/2\n",
    "\n",
    "## Convert the model coefficients (weights/biases) to H2O Frames\n",
    "H2O_w = [h2o.H2OFrame(np.transpose(c)) for c in avg_coeffs[0:num_weights]]\n",
    "H2O_b = [h2o.H2OFrame(np.transpose(np.matrix(c))) for c in avg_coeffs[num_weights:2*num_weights]]\n",
    "\n",
    "print [c.dim for c in H2O_w]\n",
    "print [c.dim for c in H2O_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "deeplearning Model Build Progress: [                                                  ] 00%\n"
     ]
    }
   ],
   "source": [
    "#Initialize an H2O Model with those weights/biases\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n",
    "\n",
    "## Create an H2O Deep Learning model from the TensorFlow model\n",
    "dlmodel = H2ODeepLearningEstimator(\n",
    "    model_id=\"model_from_TF\", ## we want to be able to find the model in Flow later\n",
    "    hidden=[HN,HN],           ## same Network layout as TF - two hidden layers\n",
    "    epochs=0,                 ## no training done in H2O - just copy over the model from TF\n",
    "    ignore_const_cols=False,  ## keep all input features (unless we also drop const cols in TF)\n",
    "    sparse=True,              ## faster as 0 input remains 0 -> sparse activation -> sparse updates\n",
    "    variable_importances=True\n",
    "    ### Initialize the H2O model with the TensorFlow model state\n",
    "    ### Requires H2O 3.8.2.1 or later\n",
    "    ,initial_weights=[H2O_w[0],H2O_w[1],H2O_w[2]]\n",
    "    ,initial_biases =[H2O_b[0],H2O_b[1],H2O_b[2]]\n",
    ")\n",
    "train_frame[784] = train_frame[784].asfactor()\n",
    "dlmodel.train(x=list(range(784)),y=784,training_frame=train_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.776672380164\n",
      "R^2: 0.907375768031\n",
      "LogLoss: 2.24261957004\n",
      "\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>15.0</td>\n",
       "<td>11.0</td>\n",
       "<td>0.0</td>\n",
       "<td>271.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>682.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>980 / 980</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>338.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>797.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1,135 / 1,135</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>218.0</td>\n",
       "<td>42.0</td>\n",
       "<td>0.0</td>\n",
       "<td>104.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>668.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.7887597</td>\n",
       "<td>814 / 1,032</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>36.0</td>\n",
       "<td>0.0</td>\n",
       "<td>94.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>877.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9643564</td>\n",
       "<td>974 / 1,010</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>38.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>938.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.9989817</td>\n",
       "<td>981 / 982</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>184.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>707.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.7937220</td>\n",
       "<td>708 / 892</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>6.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>461.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>486.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>958 / 958</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0</td>\n",
       "<td>374.0</td>\n",
       "<td>0.0</td>\n",
       "<td>8.0</td>\n",
       "<td>637.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9922179</td>\n",
       "<td>1,020 / 1,028</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>52.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>919.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0564682</td>\n",
       "<td>55 / 974</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>373.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>633.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1,009 / 1,009</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>246.0</td>\n",
       "<td>103.0</td>\n",
       "<td>2.0</td>\n",
       "<td>2289.0</td>\n",
       "<td>0.0</td>\n",
       "<td>9.0</td>\n",
       "<td>7344.0</td>\n",
       "<td>7.0</td>\n",
       "<td>0.8634</td>\n",
       "<td>8,634 / 10,000</td></tr></table></div>"
      ],
      "text/plain": [
       "0    1    2    3    4    5     6    7    8     9    Error      Rate\n",
       "---  ---  ---  ---  ---  ----  ---  ---  ----  ---  ---------  --------------\n",
       "0    0    15   11   0    271   0    0    682   1    1          980 / 980\n",
       "0    0    0    0    0    338   0    0    797   0    1          1,135 / 1,135\n",
       "0    0    218  42   0    104   0    0    668   0    0.78876    814 / 1,032\n",
       "0    0    3    36   0    94    0    0    877   0    0.964356   974 / 1,010\n",
       "0    0    0    1    1    38    0    0    938   4    0.998982   981 / 982\n",
       "0    0    0    1    0    184   0    0    707   0    0.793722   708 / 892\n",
       "0    0    6    2    1    461   0    1    486   1    1          958 / 958\n",
       "0    0    2    6    0    374   0    8    637   1    0.992218   1,020 / 1,028\n",
       "0    0    1    2    0    52    0    0    919   0    0.0564682  55 / 974\n",
       "0    0    1    2    0    373   0    0    633   0    1          1,009 / 1,009\n",
       "0    0    246  103  2    2289  0    9    7344  7    0.8634     8,634 / 10,000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.1366</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.2471</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.4055</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.56</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.6724</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.708</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.7831</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.8063</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.9607</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.1366\n",
       "2    0.2471\n",
       "3    0.4055\n",
       "4    0.56\n",
       "5    0.6724\n",
       "6    0.708\n",
       "7    0.7831\n",
       "8    0.8063\n",
       "9    0.9607\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We can let H2O evaluate the performance of the TensorFlow model on the test set\n",
    "dlmodel.model_performance(test_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8634"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Overall classification error of the TF model (in H2O form) on the test set - not very good yet - needs more training\n",
    "dlmodel.model_performance(test_frame).confusion_matrix()['Error'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "deeplearning Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "## Train in H2O for 1 more epoch (one full pass over the training data)\n",
    "dlmodel.epochs=1\n",
    "dlmodel.train(x=list(range(784)),y=784,training_frame=train_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0786"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check the classification error of the H2O model after a bit of training in H2O - much better!\n",
    "p=dlmodel.model_performance(test_frame)\n",
    "p.confusion_matrix()['Error'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
