{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O & TensorFlow Deep Learning Demo\n",
    "\n",
    "### Introduction\n",
    "In this tutorial, we'll build a simple 2-layer deep artificial neural network to classify handwritten digits [MNIST](http://yann.lecun.com/exdb/mnist/). If you are not familiar with these terms, please check out our [Deep Learning Booklet](https://github.com/h2oai/h2o-3/blob/master/h2o-docs/src/booklets/v2_2015/PDFs/online/DeepLearning_Vignette.pdf).\n",
    "\n",
    "### Prerequisites\n",
    "1. Install TensorFlow from [https://www.tensorflow.org](https://www.tensorflow.org)\n",
    "2. Download Sparkling Water from [http://www.h2o.ai/download/sparkling-water/spark16](http://www.h2o.ai/download/sparkling-water/spark16)\n",
    "3. Follow [instructions to setup PySparkling](http://www.h2o.ai/download/sparkling-water/spark16#pysparkling) (especially steps 1 and 2)\n",
    "4. Launch a Jupyter Notebook that connects to PySparkling:\n",
    "                                              \n",
    "```\n",
    "cd ~/spark-1.6.1-bin-hadoop2.6\n",
    "export SPARK_HOME=`pwd`\n",
    "export MASTER=\"local-cluster[3,2,1024]\" \n",
    "cd ~/sparkling-water-1.6.5\n",
    "IPYTHON_OPTS=\"notebook\" bin/pysparkling                                              \n",
    "```\n",
    "                                                                              \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to H2O and Import MNIST dataset\n",
    "\n",
    "We connect to an H2O cluster (here: 3 nodes), and import the MNIST dataset (pre-split into 60k rows for training and 10k rows for testing). Each row has 28^2=784 grayscale pixel values from 0 to 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import H2O and TensorFlow\n",
    "import h2o\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:92: DeprecationWarning: DisplayFormatter._ipython_display_formatter_default is deprecated: use @default decorator instead.\n",
      "  def _ipython_display_formatter_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:98: DeprecationWarning: DisplayFormatter._formatters_default is deprecated: use @default decorator instead.\n",
      "  def _formatters_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime: </td>\n",
       "<td>7 seconds 702 milliseconds </td></tr>\n",
       "<tr><td>H2O cluster version: </td>\n",
       "<td>3.8.2.6</td></tr>\n",
       "<tr><td>H2O cluster name: </td>\n",
       "<td>sparkling-water-jchow_1479130325</td></tr>\n",
       "<tr><td>H2O cluster total nodes: </td>\n",
       "<td>3</td></tr>\n",
       "<tr><td>H2O cluster total free memory: </td>\n",
       "<td>2.88 GB</td></tr>\n",
       "<tr><td>H2O cluster total cores: </td>\n",
       "<td>24</td></tr>\n",
       "<tr><td>H2O cluster allowed cores: </td>\n",
       "<td>24</td></tr>\n",
       "<tr><td>H2O cluster healthy: </td>\n",
       "<td>True</td></tr>\n",
       "<tr><td>H2O Connection ip: </td>\n",
       "<td>172.16.2.89</td></tr>\n",
       "<tr><td>H2O Connection port: </td>\n",
       "<td>54327</td></tr>\n",
       "<tr><td>H2O Connection proxy: </td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python Version: </td>\n",
       "<td>2.7.6</td></tr></table></div>"
      ],
      "text/plain": [
       "------------------------------  --------------------------------\n",
       "H2O cluster uptime:             7 seconds 702 milliseconds\n",
       "H2O cluster version:            3.8.2.6\n",
       "H2O cluster name:               sparkling-water-jchow_1479130325\n",
       "H2O cluster total nodes:        3\n",
       "H2O cluster total free memory:  2.88 GB\n",
       "H2O cluster total cores:        24\n",
       "H2O cluster allowed cores:      24\n",
       "H2O cluster healthy:            True\n",
       "H2O Connection ip:              172.16.2.89\n",
       "H2O Connection port:            54327\n",
       "H2O Connection proxy:\n",
       "Python Version:                 2.7.6\n",
       "------------------------------  --------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2OContext: ip=172.16.2.89, port=54327 (open UI at http://172.16.2.89:54327 )\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "## Read MNIST data into H2O\n",
    "from pysparkling import H2OContext\n",
    "h2o.__version__\n",
    "hc = H2OContext(sc).start()\n",
    "print(hc)\n",
    "DATASET_DIR=\"http://s3.amazonaws.com/h2o-public-test-data/bigdata/laptop/mnist\"\n",
    "train_frame = h2o.import_file(\"{}/{}\".format(DATASET_DIR, \"train.csv.gz\"))\n",
    "test_frame = h2o.import_file(\"{}/{}\".format(DATASET_DIR, \"test.csv.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## can simulate larger clusters here\n",
    "NODES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sparkling, TensorFlow!', 'Sparkling, TensorFlow!', 'Sparkling, TensorFlow!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Initialize TensorFlow session and test it\n",
    "def map_fun(i):\n",
    "  import tensorflow as tf\n",
    "  with tf.Graph().as_default() as g:\n",
    "    hello = tf.constant('Sparkling, TensorFlow!', name=\"hello_constant\")\n",
    "    with tf.Session() as sess:\n",
    "      return sess.run(hello)\n",
    "sc.parallelize(range(NODES), NODES).map(map_fun).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = hc.as_spark_frame(train_frame).repartition(NODES)\n",
    "test_df = hc.as_spark_frame(test_frame).repartition(NODES)\n",
    "#train_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a TensorFlow Deep Learning model \n",
    "Now, we define a TensorFlow Deep Learning model with 2 hidden layers of 50 neurons each, and the Rectifier activation function. We use the Softmax function to turn the 10 output neuron activation values into 10 class probabilities. We initialize the weights and biases with Gaussian noise. We train the model with Gradient descent with a fixed learning rate, no momentum, and use mini-batch for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define the number of hidden neurons per layer\n",
    "HN=50\n",
    "\n",
    "# - it loads local training data into numpy array (from Spark -> Python)\n",
    "# - train TF Deep Learning model with 2 hidden layer\n",
    "# - output accuracy on training data\n",
    "def create_nn(data_train, data_test, iterations, batch_size):\n",
    "    ## input\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    ## weights\n",
    "    W = [tf.Variable(tf.random_normal([784,HN],stddev=0.1))\n",
    "        ,tf.Variable(tf.random_normal([HN, HN],stddev=0.1))\n",
    "        ,tf.Variable(tf.random_normal([HN, 10],stddev=0.1))]\n",
    "    ## biases\n",
    "    b = [tf.Variable(tf.random_normal([HN],    stddev=0.1))\n",
    "        ,tf.Variable(tf.random_normal([HN],    stddev=0.1))\n",
    "        ,tf.Variable(tf.random_normal([10],    stddev=0.1))]\n",
    "    ## hidden layer activation\n",
    "    h1 = tf.nn.relu(   tf.matmul(x,  W[0]) + b[0])\n",
    "    h2 = tf.nn.relu(   tf.matmul(h1, W[1]) + b[1])\n",
    "    ## output\n",
    "    y = tf.nn.softmax( tf.matmul(h2, W[2]) + b[2])\n",
    "    ## storage for actual labels\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "    ## cost function\n",
    "    cross_entropy = -tf.reduce_sum(y_*tf.log(y))                    \n",
    "    ## optimizer\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "    \n",
    "    # Train the model\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    print(\"Training TensorFlow Deep Learning model\")\n",
    "    for i in range(iterations):\n",
    "      #print(\"TensorFlow iter: \", i, \" session: \", sess)\n",
    "      batch_xs, batch_ys = data_train.next_batch(batch_size)\n",
    "      sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        \n",
    "    model = [(sess.run(W[0]),sess.run(W[1]),sess.run(W[2]),sess.run(b[0]),sess.run(b[1]),sess.run(b[2]))]\n",
    "\n",
    "    # Model evaluation\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    batch_xs, batch_ys = data_test.next_batch(batch_size)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Training Accuracy:\", sess.run(accuracy, feed_dict={x: batch_xs, y_: batch_ys}))\n",
    "    #print(sess.run(tf.argmax(y,1), feed_dict={x: batch_xs, y_: batch_ys}))\n",
    "    \n",
    "    sess.close()\n",
    "    return iter(model)\n",
    "    \n",
    "    # Export the model\n",
    "    #from tensorflow_serving.session_bundle import exporter\n",
    "    #export_path = \"/tmp/xxx/\"\n",
    "    #saver = tf.train.Saver(sharded=True)\n",
    "    #model_exporter = exporter.Exporter(saver)\n",
    "    #signature = exporter.classification_signature(input_tensor=x, scores_tensor=y)\n",
    "    #model_exporter.init(sess.graph.as_graph_def(), default_graph_signature=signature)\n",
    "    #model_exporter.export(export_path, tf.constant(FLAGS.export_version), sess)\n",
    "    \n",
    "## Internal Helpers\n",
    "\n",
    "# Sampling with replacement to provide a batch size\n",
    "# Load everything into numpy datastructure\n",
    "import numpy as np\n",
    "\n",
    "def expand1hot(response, levels):\n",
    "    nrows = response.shape[0]\n",
    "    result = np.zeros((nrows, levels), dtype=np.float32)\n",
    "    result[np.arange(nrows), response.astype(np.int8)] = 1.0\n",
    "    return result\n",
    "\n",
    "class RowData:\n",
    "    def __init__(self, it):\n",
    "        self._part_array = np.array([ [a for a in x] for x in it], dtype=np.float32)\n",
    "        # Definition of input features\n",
    "        self._x = range(784)\n",
    "        # Index of response\n",
    "        self._y = 784\n",
    "\n",
    "    def next_batch(self, n):\n",
    "        # Sample from local data without replacement\n",
    "        dim = self._part_array.shape[0] # number of rows\n",
    "        sample = np.random.choice(dim, n, replace=False)\n",
    "        data = self._part_array[sample, :]\n",
    "        # Data coming from H2O, pixel values are 0..255 -> normalize to 0..1\n",
    "        # FIXME: this should be done via RDD or H2O API directly !\n",
    "        train = data[:, self._x]/255\n",
    "        response = expand1hot(data[:, self._y], 10)\n",
    "        return (train, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run TensorFlow on each H2O/PySparkling node\n",
    "\n",
    "We use the Spark Map/Reduce paradigm to distribute the training across multiple worker nodes, each node trains on its local data (stored in H2O, accessed by TensorFlow via JVM -> Python serialization provided by the PySpark(ling) API).\n",
    "\n",
    "Here, we train only for a short time for demo purposes. This is certainly not the best quality model we can build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of batches to iterate\n",
    "ITERATIONS = 100\n",
    "# Batch size (per iteration)\n",
    "BATCH_SIZE = 100\n",
    "# Use MNIST dataset provided by TensorFlow - for debugging only\n",
    "USE_TF_MNIST=False\n",
    "\n",
    "def train_nn(iterations, batch_size, use_tf_mnist=False):\n",
    "    def perPartition(it):\n",
    "        if not use_tf_mnist:\n",
    "            train_data = RowData(it)\n",
    "            test_data = train_data\n",
    "        else:\n",
    "            from tensorflow.examples.tutorials.mnist import input_data\n",
    "            mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "            train_data = mnist.train\n",
    "            test_data = mnist.train\n",
    "            \n",
    "        return create_nn(train_data, test_data, iterations, batch_size)\n",
    "        \n",
    "    return perPartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coeffs_per_node = train_df.mapPartitions(train_nn(ITERATIONS, BATCH_SIZE, USE_TF_MNIST)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Now, we have the weights and biases for each node\n",
    "print(len(coeffs_per_node))    ## Number of nodes\n",
    "print(len(coeffs_per_node[0])) ## Number of weight and bias arrays "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the TensorFlow model into a H2O Deep Learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "[[50, 784], [50, 50], [10, 50]]\n",
      "[[50, 1], [50, 1], [10, 1]]\n"
     ]
    }
   ],
   "source": [
    "# Average the weights and biases across all node-local models\n",
    "avg_coeffs = [c for c in coeffs_per_node[0]]\n",
    "for i in range(0,len(avg_coeffs)):\n",
    "    for node in range(1,NODES):\n",
    "        avg_coeffs[i] = avg_coeffs[i] + coeffs_per_node[node][i]\n",
    "avg_coeffs = [c/NODES for c in avg_coeffs]\n",
    "\n",
    "num_weights=len(coeffs_per_node[0])/2\n",
    "\n",
    "## Convert the model coefficients (weights/biases) to H2O Frames\n",
    "H2O_w = [h2o.H2OFrame(np.transpose(c)) for c in avg_coeffs[0:num_weights]]\n",
    "H2O_b = [h2o.H2OFrame(np.transpose(np.matrix(c))) for c in avg_coeffs[num_weights:2*num_weights]]\n",
    "\n",
    "print [c.dim for c in H2O_w]\n",
    "print [c.dim for c in H2O_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "deeplearning Model Build Progress: [                                                  ] 00%\n"
     ]
    }
   ],
   "source": [
    "#Initialize an H2O Model with those weights/biases\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n",
    "\n",
    "## Create an H2O Deep Learning model from the TensorFlow model\n",
    "dlmodel = H2ODeepLearningEstimator(\n",
    "    model_id=\"model_from_TF\", ## we want to be able to find the model in Flow later\n",
    "    hidden=[HN,HN],           ## same Network layout as TF - two hidden layers\n",
    "    epochs=0,                 ## no training done in H2O - just copy over the model from TF\n",
    "    ignore_const_cols=False,  ## keep all input features (unless we also drop const cols in TF)\n",
    "    sparse=True,              ## faster as 0 input remains 0 -> sparse activation -> sparse updates\n",
    "    variable_importances=True\n",
    "    ### Initialize the H2O model with the TensorFlow model state\n",
    "    ### Requires H2O 3.8.2.1 or later\n",
    "    ,initial_weights=[H2O_w[0],H2O_w[1],H2O_w[2]]\n",
    "    ,initial_biases =[H2O_b[0],H2O_b[1],H2O_b[2]]\n",
    ")\n",
    "train_frame[784] = train_frame[784].asfactor()\n",
    "dlmodel.train(x=list(range(784)),y=784,training_frame=train_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score the H2O Deep Learning model in H2O (with the TensorFlow state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.81\n",
      "R^2: 0.903401189728\n",
      "LogLoss: 2.30258509299\n",
      "\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>96.0</td>\n",
       "<td>111.0</td>\n",
       "<td>92.0</td>\n",
       "<td>98.0</td>\n",
       "<td>95.0</td>\n",
       "<td>77.0</td>\n",
       "<td>97.0</td>\n",
       "<td>117.0</td>\n",
       "<td>89.0</td>\n",
       "<td>108.0</td>\n",
       "<td>0.9020408</td>\n",
       "<td>884 / 980</td></tr>\n",
       "<tr><td>117.0</td>\n",
       "<td>113.0</td>\n",
       "<td>123.0</td>\n",
       "<td>121.0</td>\n",
       "<td>109.0</td>\n",
       "<td>104.0</td>\n",
       "<td>113.0</td>\n",
       "<td>117.0</td>\n",
       "<td>118.0</td>\n",
       "<td>100.0</td>\n",
       "<td>0.9004405</td>\n",
       "<td>1,022 / 1,135</td></tr>\n",
       "<tr><td>107.0</td>\n",
       "<td>95.0</td>\n",
       "<td>98.0</td>\n",
       "<td>92.0</td>\n",
       "<td>102.0</td>\n",
       "<td>90.0</td>\n",
       "<td>103.0</td>\n",
       "<td>126.0</td>\n",
       "<td>104.0</td>\n",
       "<td>115.0</td>\n",
       "<td>0.9050388</td>\n",
       "<td>934 / 1,032</td></tr>\n",
       "<tr><td>115.0</td>\n",
       "<td>114.0</td>\n",
       "<td>111.0</td>\n",
       "<td>98.0</td>\n",
       "<td>108.0</td>\n",
       "<td>85.0</td>\n",
       "<td>101.0</td>\n",
       "<td>97.0</td>\n",
       "<td>93.0</td>\n",
       "<td>88.0</td>\n",
       "<td>0.9029703</td>\n",
       "<td>912 / 1,010</td></tr>\n",
       "<tr><td>99.0</td>\n",
       "<td>94.0</td>\n",
       "<td>111.0</td>\n",
       "<td>119.0</td>\n",
       "<td>91.0</td>\n",
       "<td>100.0</td>\n",
       "<td>101.0</td>\n",
       "<td>84.0</td>\n",
       "<td>92.0</td>\n",
       "<td>91.0</td>\n",
       "<td>0.9073320</td>\n",
       "<td>891 / 982</td></tr>\n",
       "<tr><td>94.0</td>\n",
       "<td>78.0</td>\n",
       "<td>97.0</td>\n",
       "<td>108.0</td>\n",
       "<td>84.0</td>\n",
       "<td>82.0</td>\n",
       "<td>89.0</td>\n",
       "<td>84.0</td>\n",
       "<td>91.0</td>\n",
       "<td>85.0</td>\n",
       "<td>0.9080717</td>\n",
       "<td>810 / 892</td></tr>\n",
       "<tr><td>101.0</td>\n",
       "<td>102.0</td>\n",
       "<td>98.0</td>\n",
       "<td>85.0</td>\n",
       "<td>95.0</td>\n",
       "<td>73.0</td>\n",
       "<td>86.0</td>\n",
       "<td>98.0</td>\n",
       "<td>111.0</td>\n",
       "<td>109.0</td>\n",
       "<td>0.9102296</td>\n",
       "<td>872 / 958</td></tr>\n",
       "<tr><td>107.0</td>\n",
       "<td>115.0</td>\n",
       "<td>113.0</td>\n",
       "<td>101.0</td>\n",
       "<td>114.0</td>\n",
       "<td>88.0</td>\n",
       "<td>85.0</td>\n",
       "<td>108.0</td>\n",
       "<td>113.0</td>\n",
       "<td>84.0</td>\n",
       "<td>0.8949416</td>\n",
       "<td>920 / 1,028</td></tr>\n",
       "<tr><td>88.0</td>\n",
       "<td>92.0</td>\n",
       "<td>104.0</td>\n",
       "<td>109.0</td>\n",
       "<td>96.0</td>\n",
       "<td>91.0</td>\n",
       "<td>117.0</td>\n",
       "<td>91.0</td>\n",
       "<td>86.0</td>\n",
       "<td>100.0</td>\n",
       "<td>0.9117043</td>\n",
       "<td>888 / 974</td></tr>\n",
       "<tr><td>91.0</td>\n",
       "<td>107.0</td>\n",
       "<td>96.0</td>\n",
       "<td>114.0</td>\n",
       "<td>108.0</td>\n",
       "<td>96.0</td>\n",
       "<td>92.0</td>\n",
       "<td>113.0</td>\n",
       "<td>115.0</td>\n",
       "<td>77.0</td>\n",
       "<td>0.9236868</td>\n",
       "<td>932 / 1,009</td></tr>\n",
       "<tr><td>1015.0</td>\n",
       "<td>1021.0</td>\n",
       "<td>1043.0</td>\n",
       "<td>1045.0</td>\n",
       "<td>1002.0</td>\n",
       "<td>886.0</td>\n",
       "<td>984.0</td>\n",
       "<td>1035.0</td>\n",
       "<td>1012.0</td>\n",
       "<td>957.0</td>\n",
       "<td>0.9065</td>\n",
       "<td>9,065 / 10,000</td></tr></table></div>"
      ],
      "text/plain": [
       "0     1     2     3     4     5    6    7     8     9    Error     Rate\n",
       "----  ----  ----  ----  ----  ---  ---  ----  ----  ---  --------  --------------\n",
       "96    111   92    98    95    77   97   117   89    108  0.902041  884 / 980\n",
       "117   113   123   121   109   104  113  117   118   100  0.900441  1,022 / 1,135\n",
       "107   95    98    92    102   90   103  126   104   115  0.905039  934 / 1,032\n",
       "115   114   111   98    108   85   101  97    93    88   0.90297   912 / 1,010\n",
       "99    94    111   119   91    100  101  84    92    91   0.907332  891 / 982\n",
       "94    78    97    108   84    82   89   84    91    85   0.908072  810 / 892\n",
       "101   102   98    85    95    73   86   98    111   109  0.91023   872 / 958\n",
       "107   115   113   101   114   88   85   108   113   84   0.894942  920 / 1,028\n",
       "88    92    104   109   96    91   117  91    86    100  0.911704  888 / 974\n",
       "91    107   96    114   108   96   92   113   115   77   0.923687  932 / 1,009\n",
       "1015  1021  1043  1045  1002  886  984  1035  1012  957  0.9065    9,065 / 10,000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0935</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.194</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.2907000</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.3891000</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.4841</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.5832000</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.6896001</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.7780001</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.8741001</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0000001</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.0935\n",
       "2    0.194\n",
       "3    0.2907\n",
       "4    0.3891\n",
       "5    0.4841\n",
       "6    0.5832\n",
       "7    0.6896\n",
       "8    0.778\n",
       "9    0.8741\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We can let H2O evaluate the performance of the TensorFlow model on the test set\n",
    "dlmodel.model_performance(test_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9065"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Overall classification error of the TF model (in H2O form) on the test set - not very good yet - needs more training\n",
    "dlmodel.model_performance(test_frame).confusion_matrix()['Error'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Java scoring code (POJO) for the TensorFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dlmodel.download_pojo()  ## too large for Github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Training the Deep Learning model in H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "deeplearning Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "## Train in H2O for 1 more epoch (one full pass over the training data)\n",
    "dlmodel.epochs=1\n",
    "dlmodel.train(x=list(range(784)),y=784,training_frame=train_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7801"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check the classification error of the H2O model after a bit of training in H2O - much better!\n",
    "p=dlmodel.model_performance(test_frame)\n",
    "p.confusion_matrix()['Error'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Inspect the model in Flow\n",
    "Since the model is now in H2O, we can inspect it from [Flow](http://localhost:54321), run ```print(hc)``` to see the URL to connect to Flow.\n",
    "\n",
    "For example, we can graphically inspect the variable importance or the confusion matrix. We can also score the model on the test set in Flow, continue training the model from this checkpoint, or inspect the Java scoring code (POJO). We highly recommend you to get familiar with Flow if you're not already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
